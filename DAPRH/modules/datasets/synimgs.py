from __future__ import print_function, absolute_import
import os.path as osp
import glob
import re
import urllib
import zipfile

from .data import BaseImageDataset
# from ..utils.osutils import mkdir_if_missing
# from ..utils.serialization import write_json

ndict = {
    'dukemtmc':'DukeMTMC-reID',
    'market1501': 'Market-1501-v15.09.15',

    # 'dukemtmc-fake':'duke2mark-results',
    'dukemtmc-fake':'duke2msmt-results',
    # 'market1501-fake': 'mark2duke-results',
    'market1501-fake': 'mark2msmt-results',

    '':None
}

class SyntheImgs(BaseImageDataset):
    """
    Real image + Fake image generated by GAN
    combine from 2 folders: real + face
    real is 1
    fake is 0
    """
    dataset_dir = '.'

    def __init__(self, root="./datasets", typeds="dukemtmc", verbose=True, only_fake=False, **kwargs):
        super(SyntheImgs, self).__init__()
        self.dataset_name = 'duke'
        self.only_fake = only_fake
        self.dataset_dir = root #osp.join(root, self.dataset_dir)
        self.train_dir = osp.join(self.dataset_dir, f'{ndict[typeds]}/bounding_box_train')
        self.query_dir = osp.join(self.dataset_dir, f'{ndict[typeds]}/query')
        self.gallery_dir = osp.join(self.dataset_dir, f'{ndict[typeds]}/bounding_box_test')
        self.fake_train_dir = osp.join(self.dataset_dir, "SyntheImgs/{}".format(ndict[typeds+"-fake"]))

        #self._download_data()
        self._check_before_run()

        train = self._process_dir_train(self.train_dir, self.fake_train_dir, relabel=True)
        query = self._process_dir(self.query_dir, relabel=False)
        gallery = self._process_dir(self.gallery_dir, relabel=False)

        self.train = train
        self.query = query
        self.gallery = gallery



        train = [(f, p, c,) for f, p, c, _ in train]
        if verbose:
            print("=> Systhesing Dataset loaded")
            self.print_dataset_statistics(train, query, gallery)



        

        self.num_train_pids, self.num_train_imgs, self.num_train_cams = self.get_imagedata_info(train)
        self.num_query_pids, self.num_query_imgs, self.num_query_cams = self.get_imagedata_info(query)
        self.num_gallery_pids, self.num_gallery_imgs, self.num_gallery_cams = self.get_imagedata_info(gallery)
                

    def _check_before_run(self):
        """Check if all files are available before going deeper"""
        if not osp.exists(self.dataset_dir):
            raise RuntimeError("'{}' is not available".format(self.dataset_dir))
        if not osp.exists(self.train_dir):
            raise RuntimeError("'{}' is not available".format(self.train_dir))
        if not osp.exists(self.query_dir):
            raise RuntimeError("'{}' is not available".format(self.query_dir))
        if not osp.exists(self.gallery_dir):
            raise RuntimeError("'{}' is not available".format(self.gallery_dir))
        if not osp.exists(self.fake_train_dir):
            raise RuntimeError("'{}' is not available".format(self.fake_train_dir))

    def _process_dir(self, dir_path, relabel=False):
        img_paths = glob.glob(osp.join(dir_path, '*.jpg'))
        pattern = re.compile(r'([-\d]+)_c(\d)')

        pid_container = set()
        for img_path in img_paths:
            pid, _ = map(int, pattern.search(img_path).groups())
            pid_container.add(pid)
        pid2label = {pid: label for label, pid in enumerate(pid_container)}

        dataset = []
        for img_path in img_paths:
            pid, camid = map(int, pattern.search(img_path).groups())
            assert 1 <= camid <= 8
            camid -= 1  # index starts from 0
            if relabel: pid = pid2label[pid]
            dataset.append((img_path, pid, camid))

        return dataset

    def _process_dir_train(self, dir_path, fake_path, relabel=False, only_fake=False):
        img_paths = [] if self.only_fake else glob.glob(osp.join(dir_path, '*.jpg'))  
        fake_paths = glob.glob(osp.join(fake_path, '*.jpg'))
        pattern = re.compile(r'([-\d]+)_c(\d)')

        pid_container = set()
        
        for img_path in img_paths:
            pid, _ = map(int, pattern.search(img_path).groups())
            pid_container.add(pid)
        for img_path in fake_paths:
            pid, _ = map(int, pattern.search(img_path).groups())
            pid_container.add(pid)
        pid2label = {pid: label for label, pid in enumerate(pid_container)}

        dataset = []
        cams = []
        for img_path in img_paths:
            pid, camid = map(int, pattern.search(img_path).groups())
            # assert 1 <= camid <= 8
            camid -= 1  # index starts from 0
            cams += [camid]
            if relabel: pid = pid2label[pid]
            dataset.append((img_path, pid, camid, 1))
        for img_path in fake_paths:
            pid, camid = map(int, pattern.search(img_path).groups())
            # assert 1 <= camid <= 8
            camid += 100  # index starts from 0
            if relabel: pid = pid2label[pid]
            dataset.append((img_path, pid, camid, 0))

        return dataset
